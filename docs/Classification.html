<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Classification</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Data Science</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Regression.html">Regression</a>
</li>
<li>
  <a href="Classification.html">Classification</a>
</li>
<li>
  <a href="Clustering.html">Clustering</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Classification</h1>

</div>

<div id="TOC">
<ul>
<li><a href="#overview"><span class="toc-section-number">1</span> Overview</a></li>
<li><a href="#logistic-regression"><span class="toc-section-number">2</span> Logistic Regression</a><ul>
<li><a href="#logistic-regression-income-example"><span class="toc-section-number">2.1</span> Logistic Regression: Income Example</a></li>
</ul></li>
<li><a href="#k-nearest-neighbors-knn"><span class="toc-section-number">3</span> K-Nearest Neighbors (KNN)</a><ul>
<li><a href="#knn-iris-example"><span class="toc-section-number">3.1</span> KNN: Iris Example</a></li>
</ul></li>
<li><a href="#naive-bayes"><span class="toc-section-number">4</span> Naive Bayes</a><ul>
<li><a href="#naive-bayes-classifier"><span class="toc-section-number">4.1</span> Naive Bayes Classifier</a></li>
<li><a href="#naive-bayes-titanic-example"><span class="toc-section-number">4.2</span> Naive Bayes: Titanic Example</a></li>
<li><a href="#laplace-correction"><span class="toc-section-number">4.3</span> Laplace Correction</a></li>
</ul></li>
<li><a href="#classification-trees"><span class="toc-section-number">5</span> Classification Trees</a><ul>
<li><a href="#how-to-grow-trees"><span class="toc-section-number">5.1</span> How to Grow Trees</a></li>
<li><a href="#other-tree-based-methods"><span class="toc-section-number">5.2</span> Other Tree-Based Methods</a></li>
<li><a href="#classification-tree-carseat-sales-example"><span class="toc-section-number">5.3</span> Classification Tree: Carseat Sales Example</a></li>
<li><a href="#regression-tree-random-forest-housing-example"><span class="toc-section-number">5.4</span> Regression Tree: Random Forest Housing Example</a></li>
</ul></li>
</ul>
</div>

<div id="overview" class="section level1">
<h1><span class="header-section-number">1</span> Overview</h1>
<p>Classification is used on data where the response variable is qualitative (categorical), unlike regression which has a quantitative (continuous) response variable. The response categories are known making this a supervised learning technique, unlike clustering where the categories are unknown.</p>
<p>A common method to evaluate classification models is to calculate the accuracy: the proportion of correctly classified responses to the total number of classifications made. Other performance metrics are also useful, including sensitivity and specificity (explored with logistic regression).</p>
<p>Some common classification techniques include: logistic regression, Naive Bayes classifier, k-nearest neighbor, decision trees, linear/quadratic discriminant analysis (not explored here), and support vector machines (not explored here).</p>
</div>
<div id="logistic-regression" class="section level1">
<h1><span class="header-section-number">2</span> Logistic Regression</h1>
<p>Logistic regression is used for binary classification - when there are 2 possible predictor classes.</p>
<p>Logistic regression assumes a linear relationship between the predictors variables and the log-odds of the event Y=1: <span class="math display">\[log_b\frac{p}{1-p} = \beta_0 + \beta_1x_1 + \beta_2x_2\]</span> where <span class="math inline">\(p = P(Y=1).\)</span> We can solve for <span class="math inline">\(p\)</span>: <span class="math display">\[p = \frac{b^{\beta_0 + \beta_1x_1 + \beta_2x_2}}{b^{\beta_0 + \beta_1x_1 + \beta_2x_2}+1} = \frac{1}{1+b^{-(\beta_0 + \beta_1x_1 + \beta_2x_2)}}\]</span></p>
<p>Generally <span class="math inline">\(e\)</span> is chosen for the base <span class="math inline">\(b\)</span>, though other bases are possible. The regression coefficients are often found with a maximum likelihood estimation that requires an iterative process.</p>
<p><strong>Assumptions:</strong> logistic regression requires the observations to be independent, little to no multicollinearity among independent variables, and linearity of independent variables and log odds.</p>
<div id="logistic-regression-income-example" class="section level2">
<h2><span class="header-section-number">2.1</span> Logistic Regression: Income Example</h2>
<p>We want to predict if an individual will earn more than $50K using various predictors. This example was inspired by <a href="http://r-statistics.co/Logistic-Regression-With-R.html">Logistic Regression Income</a></p>
<div id="traintest-set" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Train/Test Set</h3>
<p>Load data:</p>
<pre class="r"><code>incomeData &lt;- read.table(&#39;adult.data&#39;, sep = &#39;,&#39;, fill = F, strip.white = T)
colnames(incomeData) &lt;- c(&#39;age&#39;, &#39;workclass&#39;, &#39;fnlwgt&#39;, &#39;education&#39;, &#39;education_num&#39;, &#39;marital_status&#39;, &#39;occupation&#39;, &#39;relationship&#39;, &#39;race&#39;, &#39;sex&#39;, &#39;capital_gain&#39;, &#39;capital_loss&#39;, &#39;hours_per_week&#39;, &#39;native_country&#39;, &#39;income&#39;)
incomeData$IncomeAbove50 = as.numeric(incomeData$income == &#39;&gt;50K&#39;)
table(incomeData$income)</code></pre>
<pre><code>## 
## &lt;=50K  &gt;50K 
## 24720  7841</code></pre>
<p>We see there are significantly more cases of &lt;=50K than &gt;50K. Because of this class bias, we will select our training data proportionately from each of these classes.</p>
<pre class="r"><code>dataAbove = incomeData %&gt;% filter(IncomeAbove50 == 1)
dataBelow = incomeData %&gt;% filter(IncomeAbove50 == 0)
set.seed(123)
dataAbove_trainingRows = sample(1:nrow(dataAbove), 0.75*nrow(dataAbove))
dataBelow_trainingRows = sample(1:nrow(dataBelow), 0.75*nrow(dataBelow))
trainAbove = dataAbove[dataAbove_trainingRows,]
trainBelow = dataBelow[dataBelow_trainingRows,]
train = rbind(trainAbove, trainBelow)

testAbove = dataAbove[-dataAbove_trainingRows,]
testBelow = dataBelow[-dataBelow_trainingRows,]
test = rbind(testAbove, testBelow)

table(train$income)</code></pre>
<pre><code>## 
## &lt;=50K  &gt;50K 
## 18540  5880</code></pre>
<pre class="r"><code>rm(dataAbove, dataBelow, dataAbove_trainingRows, dataBelow_trainingRows, trainAbove, trainBelow, testAbove, testBelow)</code></pre>
<p>We have a similar proportion of &gt;50K to &lt;=50K in our training data as in the full data set.</p>
</div>
<div id="fit-and-test-logistic-model" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Fit and Test Logistic Model</h3>
<p>I chose variables I thought would predict <em>income</em>, however different variable choices or variable selection methods could be used.</p>
<pre class="r"><code>mod.logit = glm(IncomeAbove50 ~ age + workclass + education_num + sex + hours_per_week, data=train, family=&#39;binomial&#39;)
summary(mod.logit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = IncomeAbove50 ~ age + workclass + education_num + 
##     sex + hours_per_week, family = &quot;binomial&quot;, data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.7015  -0.6631  -0.4058  -0.1008   3.2307  
## 
## Coefficients:
##                             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                -9.999517   0.173092 -57.770  &lt; 2e-16 ***
## age                         0.048093   0.001439  33.422  &lt; 2e-16 ***
## workclassFederal-gov        1.238134   0.133968   9.242  &lt; 2e-16 ***
## workclassLocal-gov          0.815840   0.119628   6.820 9.12e-12 ***
## workclassNever-worked      -9.351303 201.406410  -0.046 0.962968    
## workclassPrivate            0.871994   0.104582   8.338  &lt; 2e-16 ***
## workclassSelf-emp-inc       1.374228   0.130409  10.538  &lt; 2e-16 ***
## workclassSelf-emp-not-inc   0.431777   0.117644   3.670 0.000242 ***
## workclassState-gov          0.656341   0.132591   4.950 7.42e-07 ***
## workclassWithout-pay      -11.954790 148.161877  -0.081 0.935691    
## education_num               0.353197   0.007808  45.233  &lt; 2e-16 ***
## sexMale                     1.192198   0.044124  27.019  &lt; 2e-16 ***
## hours_per_week              0.034253   0.001552  22.077  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 26959  on 24419  degrees of freedom
## Residual deviance: 20733  on 24407  degrees of freedom
## AIC: 20759
## 
## Number of Fisher Scoring iterations: 12</code></pre>
<p>Predict for the test data</p>
<pre class="r"><code>predictedProbability = predict(mod.logit, test, type=&#39;response&#39;)
test$PredictedIncomeAbove50 = ifelse(predictedProbability &gt; 0.5,1,0)
confusionMatrix(factor(test$PredictedIncomeAbove50), factor(test$IncomeAbove50), positive = &#39;1&#39;)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 5768 1152
##          1  412  809
##                                           
##                Accuracy : 0.8079          
##                  95% CI : (0.7992, 0.8164)
##     No Information Rate : 0.7591          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.397           
##                                           
##  Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
##                                           
##             Sensitivity : 0.41254         
##             Specificity : 0.93333         
##          Pos Pred Value : 0.66257         
##          Neg Pred Value : 0.83353         
##              Prevalence : 0.24088         
##          Detection Rate : 0.09937         
##    Detection Prevalence : 0.14998         
##       Balanced Accuracy : 0.67294         
##                                           
##        &#39;Positive&#39; Class : 1               
## </code></pre>
<p>Our model predicts our test data with 81% accuracy where accuracy = <span class="math inline">\(\frac{TP + FN}{Total}\)</span> Some other interesting metrics:</p>
<ul>
<li>Sensitivity: also called recall or true positive rate. Equal to <span class="math inline">\(\frac{TP}{TP + FN}\)</span> where <span class="math inline">\(FN\)</span> (Type II error) occurs when the model predicts a true value to be false<br />
</li>
<li>Specificity: also called true negative rate. Equal to <span class="math inline">\(\frac{TN}{TN + FP}\)</span> where <span class="math inline">\(FP\)</span> (Type I error) occurs when the model predicts a false value to be true</li>
</ul>
<p>Generally raising one of the metrics lowers the other (trade-off), the context of the data will determine which is more important.</p>
<p>The model prediction returns a probability of each observation having an income greater than 50K. Here, we classified observations with a probability &gt; 0.5 to have an income greater than 50K, however different threshold values are possible.</p>
</div>
<div id="roc-curve" class="section level3">
<h3><span class="header-section-number">2.1.3</span> ROC Curve</h3>
<p>A receiver operating characteristic (ROC) curve plots the true positive rate (sensitivity) against the false positive rate (1 - specificity). This can also be viewed as the percent of positive outcomes versus the percent of other outcomes.</p>
<pre class="r"><code>library(ROCR)
pred = prediction(predictedProbability, test$IncomeAbove50)
perf = performance(pred, measure = &#39;tpr&#39;, x.measure = &#39;fpr&#39;)
plot(perf)</code></pre>
<p><img src="Classification_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The curve will generally be above the line <span class="math inline">\(y=x\)</span> and curves of “better” models are typically close to the upper left corner.</p>
<p>We can also calculate the area under the ROC curve (AUC)</p>
<pre class="r"><code>auc = performance(pred, measure = &quot;auc&quot;)
auc = auc@y.values[[1]]
auc</code></pre>
<pre><code>## [1] 0.8195055</code></pre>
<p>“Better” models generally have AUC close to 1, though it’s important to consider many metrics when evaluating a model.</p>
</div>
<div id="model-assumptions" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Model Assumptions</h3>
<p>We can check for multicollinearity among our independent variables by computing the variance inflation factor (VIF). All the variables should have a VIF less than 10 but ideally less than 5.</p>
<pre class="r"><code>vif(mod.logit)</code></pre>
<pre><code>##                    GVIF Df GVIF^(1/(2*Df))
## age            1.102818  1        1.050151
## workclass      1.157198  8        1.009167
## education_num  1.047505  1        1.023477
## sex            1.039897  1        1.019753
## hours_per_week 1.074034  1        1.036356</code></pre>
</div>
</div>
</div>
<div id="k-nearest-neighbors-knn" class="section level1">
<h1><span class="header-section-number">3</span> K-Nearest Neighbors (KNN)</h1>
<p>KNN works by considering the K training data points that are closest (typically using Euclidean distance) to the test observation. Then, the test observation is predicted to be in the same class as the majority of the closest training points. In the event of a tie, one of the classes is randomly chosen. It is necessary to normalize (generally min-max normalization instead of standardization) the data first since we will be calculating distances.</p>
<div id="knn-iris-example" class="section level2">
<h2><span class="header-section-number">3.1</span> KNN: Iris Example</h2>
<p>This example was inspired by <a href="https://towardsdatascience.com/k-nearest-neighbors-algorithm-with-examples-in-r-simply-explained-knn-1f2c88da405c">KNN Example</a>. Normalize the iris data and split into a training and test set</p>
<pre class="r"><code>normalize &lt;- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
set.seed(123)
irisNormalized = as.data.frame(lapply(iris[,c(1,2,3,4)], normalize))
training_ind = sample(1:nrow(iris), 0.75 * nrow(iris))
train = irisNormalized[training_ind,]
test = irisNormalized[-training_ind,]
train_class = iris[training_ind,5]
test_class = iris[-training_ind,5]</code></pre>
<p>Now run knn function</p>
<pre class="r"><code>library(class)
test_prediction = knn(train, test, cl=train_class, k=3)</code></pre>
<p>Calculate accuracy of test data</p>
<pre class="r"><code>table(test_prediction, test_class)</code></pre>
<pre><code>##                test_class
## test_prediction setosa versicolor virginica
##      setosa         12          0         0
##      versicolor      0         16         1
##      virginica       0          1         8</code></pre>
<pre class="r"><code>mean(test_prediction == test_class)*100 #accuracy</code></pre>
<pre><code>## [1] 94.73684</code></pre>
<p>Try a larger value of k (consider more neighbors)</p>
<pre class="r"><code>test_prediction = knn(train, test, cl=train_class, k=11)
table(test_prediction, test_class)</code></pre>
<pre><code>##                test_class
## test_prediction setosa versicolor virginica
##      setosa         12          0         0
##      versicolor      0         16         0
##      virginica       0          1         9</code></pre>
<pre class="r"><code>mean(test_prediction == test_class)*100 #accuracy</code></pre>
<pre><code>## [1] 97.36842</code></pre>
<p>In this case, a larger k increased the accuracy of the model, however this was inconsistent across different splits of the training and test sets. We could use cross-validation to test different values of k (and different train/test sets) to determine the optimal number of neighbors to use.</p>
<p>In general, a smaller value of k means noise in the data will have a higher influence on the boundary causing the boundary to be more flexible. A larger value of k will have smoother decision boundaries which may not pick up on some boundaries of the data, and is more computationally expensive.</p>
<p>A general rule is to choose <span class="math inline">\(k=\sqrt{N}\)</span> where N is the number of samples in the training data.</p>
</div>
</div>
<div id="naive-bayes" class="section level1">
<h1><span class="header-section-number">4</span> Naive Bayes</h1>
<p>Bayes theorem is given as: <span class="math display">\[p(C_k|\textbf{x}) = \frac{p(C_k)p(\textbf{x}|C_k)}{p(\textbf{x})}\]</span> where  represents the features in the data, <span class="math inline">\(C_k\)</span> is a possible class, and <span class="math inline">\(p(C_k|\textbf{x})\)</span> is the probability of belonging to a class given the independent variables defined by . This is sometimes rewritten as <span class="math display">\[\text{posterior} = \frac{\text{prior}\times \text{likelihood}}{\text{evidence}}\]</span></p>
<p>The denominator of the fraction is constant, and the numerator is equivalent to the joint probability model <span class="math inline">\(p(C_k,x_1,...,x_n)\)</span>.</p>
<p>If we assume all features in  are mutually independent (this assumption is what makes it <em>naive</em>), we can rewrite Bayes theorem as <span class="math display">\[p(C_k|x_1,...,x_n) \propto p(C_k) \prod_{i=1}^n p(x_i|C_k)\]</span></p>
<div id="naive-bayes-classifier" class="section level2">
<h2><span class="header-section-number">4.1</span> Naive Bayes Classifier</h2>
<p>Assign a class label <span class="math inline">\(\hat{y} = C_k\)</span> for some k where <span class="math display">\[\hat{y} = \text{argmax}_{k \in \{1,...,K\}}p(C_k)\prod_{i=1}^n p(x_i|C_k)\]</span></p>
</div>
<div id="naive-bayes-titanic-example" class="section level2">
<h2><span class="header-section-number">4.2</span> Naive Bayes: Titanic Example</h2>
<p>Naive Bayes is good to use when all the predictors are categorical, but can also be used on continuous predictors. It also works well when there are more than 2 classes to predict, unlike other classification methods (e.g. logistic regression). This example was inspired by <a href="https://www.r-bloggers.com/understanding-naive-bayes-classifier-using-r/">Naive Bayes Blog Post</a></p>
<p>We try to predict if a passenger survived on the Titanic given the predictors: Class (1st, 2nd, 3rd, crew), Sex (M,F), and Age (child, adult).</p>
<pre class="r"><code>data(&quot;Titanic&quot;)
Titanic = as.data.frame(Titanic)
#Data currently summary data, expand for analysis
repeating_sequence=rep.int(seq_len(nrow(Titanic)), Titanic$Freq)
Titanic_df=Titanic[repeating_sequence,]
Titanic_df = Titanic_df %&gt;% select(-Freq)</code></pre>
<p>Fit Naive Bayes model</p>
<pre class="r"><code>library(e1071)</code></pre>
<pre><code>## Warning: package &#39;e1071&#39; was built under R version 3.6.3</code></pre>
<pre class="r"><code>mod.NB = naiveBayes(Survived~., data=Titanic_df)
mod.NB</code></pre>
<pre><code>## 
## Naive Bayes Classifier for Discrete Predictors
## 
## Call:
## naiveBayes.default(x = X, y = Y, laplace = laplace)
## 
## A-priori probabilities:
## Y
##       No      Yes 
## 0.676965 0.323035 
## 
## Conditional probabilities:
##      Class
## Y            1st        2nd        3rd       Crew
##   No  0.08187919 0.11208054 0.35436242 0.45167785
##   Yes 0.28551336 0.16596343 0.25035162 0.29817159
## 
##      Sex
## Y           Male     Female
##   No  0.91543624 0.08456376
##   Yes 0.51617440 0.48382560
## 
##      Age
## Y          Child      Adult
##   No  0.03489933 0.96510067
##   Yes 0.08016878 0.91983122</code></pre>
<p>Make predictions and check accuracy</p>
<pre class="r"><code>Titanic_df$PredictedSurvived = predict(mod.NB, Titanic_df)
table(Titanic_df$PredictedSurvived, Titanic_df$Survived)</code></pre>
<pre><code>##      
##         No  Yes
##   No  1364  362
##   Yes  126  349</code></pre>
<pre class="r"><code>mean(Titanic_df$PredictedSurvived==Titanic_df$Survived)</code></pre>
<pre><code>## [1] 0.7782826</code></pre>
<p>The model predicts if a passenger survives with about 77.8% accuracy.</p>
</div>
<div id="laplace-correction" class="section level2">
<h2><span class="header-section-number">4.3</span> Laplace Correction</h2>
<p>Suppose there was a set of predictors with a 0 probability of one of the outcomes. For example, suppose none of the crew survived. Without any correction, our model will always predict a crew member will not survive, leaving no chance for an unforeseen circumstance.</p>
<pre class="r"><code>missingData = unique(Titanic_df %&gt;% filter(Class==&#39;Crew&#39;, Survived==&#39;Yes&#39;) %&gt;% select(Class:Survived))
Titanic_df_Less = Titanic_df %&gt;% select(Class:Survived) %&gt;% anti_join(missingData, by = c(&#39;Class&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;Survived&#39;))
mod.NBNoLaplace = naiveBayes(Survived ~ ., data=Titanic_df_Less, laplace=0)
print(missingData[1,])</code></pre>
<pre><code>##   Class  Sex   Age Survived
## 1  Crew Male Adult      Yes</code></pre>
<pre class="r"><code>predict(mod.NBNoLaplace, missingData[1,], type=&quot;raw&quot;, threshold=0)</code></pre>
<pre><code>##      No Yes
## [1,]  1 NaN</code></pre>
<p>We introduce the Laplace correction, which adds 1 (or whatever defined value) to all the classes. This forces all joint probabilities to be greater than 0 and allows a (sometimes small) possibility for all outcomes.</p>
<pre class="r"><code>mod.NBLaplace = naiveBayes(Survived ~ ., data=Titanic_df_Less, laplace=1)
predict(mod.NBLaplace, missingData[1,], type=&quot;raw&quot;, threshold=0)</code></pre>
<pre><code>##             No         Yes
## [1,] 0.9994807 0.000519274</code></pre>
</div>
</div>
<div id="classification-trees" class="section level1">
<h1><span class="header-section-number">5</span> Classification Trees</h1>
<p>Decision trees create a set of ‘questions’ to partition the data set. The questions are chosen to provide the ‘best split’, and result in a flow chart to determine the category. Content and examples for this section were taken from <a href="https://www.datacamp.com/community/tutorials/decision-trees-R">DataCamp Decision Tree Example</a></p>
<p>Terms:</p>
<ul>
<li>root node: starting node representing the entire population/sample</li>
<li>decision node: a sub-node that splits into more sub-nodes</li>
<li>terminal node/leaf: a sub-node that does not split</li>
</ul>
<p>Decision trees are intuitive and easy to explain and visualize, but are not very robust as a small change in the data can drastically change the final tree.</p>
<div id="how-to-grow-trees" class="section level2">
<h2><span class="header-section-number">5.1</span> How to Grow Trees</h2>
<div id="classification" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Classification</h3>
<p>Classification trees use divide and conquer to create the most pure (homogeneous) partitions. A common way to build these trees is to use the Gini index. This is defined as <span class="math display">\[G = \sum_{k=1}^K\hat{p}_{mk}(1-\hat{p}_{mk})\]</span> where <span class="math inline">\(\hat{p}_{mk}\)</span> is the proportion of training observations in the <em>m</em>th region that are from the <em>k</em>th class. The Gini index is a measure of total variance across the classes and is referred to as the nodes purity. The index will be small if the <span class="math inline">\(\hat{p}_{mk}\)</span> are close to 0 or 1, and the split that produces the purest (largest <em>G</em>) will be chosen.</p>
<p>Other methods of growing classification decision trees include cross-entropy (similar to Gini index) and classification error rate (generally not sensitive enough for growing trees)</p>
</div>
<div id="regression" class="section level3">
<h3><span class="header-section-number">5.1.2</span> Regression</h3>
<p>If our outcome variable were continuous, we could grow a regression tree. This uses Recursive Binary Splitting to minimize the Residual Sum of Squares (RSS), defined as <span class="math display">\[\sum_{m=1}^M\sum_{i\in R_m}(y_i-\hat{y}_{R_m})^2\]</span> where <span class="math inline">\(\hat{y}_{R_m}\)</span> is the mean response for the training observations in the <em>m</em>th region/box. In short, this is a top-down greedy approach that starts at the top of the tree and successively splits the predictor space to minimize the RSS at each split. (More details could be added but this section is focused on classification trees).</p>
</div>
<div id="pruning-trees" class="section level3">
<h3><span class="header-section-number">5.1.3</span> Pruning Trees</h3>
<p>We can pre-prune the trees by defining a maximum depth/number of levels, or by defining a minimum number of observations needed in a sub-node to continue partitioning.</p>
<p>We can also post-prune overly complicated branches when their reduction in error does not outweigh their added complexity.</p>
</div>
</div>
<div id="other-tree-based-methods" class="section level2">
<h2><span class="header-section-number">5.2</span> Other Tree-Based Methods</h2>
<p>The current methods of fitting our trees suffer from high variance, so different splits for the training/test sets can result in very different models. We briefly introduce 3 other methods of growing decision trees: Bagging, Random Forests, and Boosting.</p>
<div id="bagging-bootstrap-aggregation" class="section level3 unnumbered">
<h3>Bagging (bootstrap aggregation)</h3>
<p>Bagging randomly sample from the training data (with replacement) to split into multiple data sets, builds a decision tree classifier on each of them, then averages the resulting predictions.</p>
<p>While each tree has high variance but low bias, averaging multiple trees together reduces the variance.</p>
</div>
<div id="random-forests" class="section level3 unnumbered">
<h3>Random Forests</h3>
<p>This methods starts the same as bagging by splitting the training data. However, at each split a random subset of <em>m</em> predictors is chosen as a split candidate. If <em>m</em> equals the total number of predictors <em>p</em>, this method is equivalent to bagging.</p>
<p>Generally for classification problems <span class="math inline">\(m = \sqrt{p}\)</span> and for regression problems <span class="math inline">\(m = p/3\)</span> (rounded down).</p>
</div>
<div id="boosting" class="section level3 unnumbered">
<h3>Boosting</h3>
<p>Boosting grows trees sequentially, where each tree is grown using information from previous trees. Given a current model, we fit a decision tree to the residuals from the model. This new trees is added into the fitted function to update the residuals. Boosting has three parameters: the number of tree, the shrinkage parameter (the rate at which boosting learns), and the number of splits in each tree.</p>
</div>
</div>
<div id="classification-tree-carseat-sales-example" class="section level2">
<h2><span class="header-section-number">5.3</span> Classification Tree: Carseat Sales Example</h2>
<p>Our goal is to predict if the carseat sales are greater than 8000 units or not.</p>
<pre class="r"><code>library(ISLR)
library(rpart)
set.seed(123) #rpart performs cross validation so we set our random number seed
carseats = Carseats
carseats$High = factor(ifelse(carseats$Sales&lt;=8, &quot;No&quot;, &quot;Yes&quot;))
mod.tree = rpart(High~.-Sales, data=carseats) #could alternatively use tree
#summary(mod.tree)
mod.tree$cptable</code></pre>
<pre><code>##           CP nsplit rel error    xerror       xstd
## 1 0.28658537      0 1.0000000 1.0000000 0.05997967
## 2 0.10975610      1 0.7134146 0.7134146 0.05547692
## 3 0.04573171      2 0.6036585 0.6524390 0.05398236
## 4 0.03658537      4 0.5121951 0.6402439 0.05365767
## 5 0.02743902      5 0.4756098 0.6341463 0.05349198
## 6 0.02439024      7 0.4207317 0.6524390 0.05398236
## 7 0.01219512      8 0.3963415 0.6341463 0.05349198
## 8 0.01000000     10 0.3719512 0.5609756 0.05132104</code></pre>
<pre class="r"><code>mod.tree$variable.importance</code></pre>
<pre><code>##       Price   ShelveLoc         Age Advertising   CompPrice      Income  Population   Education          US 
##  39.3458304  28.9918954  13.0761815  12.7110483  10.2253806   6.2611750   3.1669718   0.9670985   0.1411614</code></pre>
<p>We can also visualize this tree:</p>
<pre class="r"><code>library(rpart.plot)
rpart.plot(mod.tree, type=4, extra=1)</code></pre>
<p><img src="Classification_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<div id="making-predictions" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Making Predictions</h3>
<p>Split into a training and test set and calculate accuracy</p>
<pre class="r"><code>set.seed(123)
train = sample(1:nrow(carseats), 250)
mod.treeTrain = rpart(High~.-Sales, carseats, subset=train)
rpart.plot(mod.treeTrain)</code></pre>
<p><img src="Classification_files/figure-html/train-1.png" width="672" /></p>
<p>Now predict the class for the test set</p>
<pre class="r"><code>test = carseats[-train,]
test$predicted = predict(mod.treeTrain, test, type=&#39;class&#39;)
table(test$High, test$predicted)</code></pre>
<pre><code>##      
##       No Yes
##   No  63  26
##   Yes 17  44</code></pre>
<pre class="r"><code>mean(test$High == test$predicted) #accuracy</code></pre>
<pre><code>## [1] 0.7133333</code></pre>
<div id="pruning-tree" class="section level4 unnumbered">
<h4>Pruning Tree</h4>
<p><strong>Pre-Pruning:</strong> This stops the growth of a tree depending on a given maximum size of the tree or a minimum number of observations needed in a sub-node to split.</p>
<p>Make a tree with maximum depth = 3</p>
<pre class="r"><code>mod.treeDepth = rpart(High~.-Sales, carseats, subset=train, method=&#39;class&#39;, control=rpart.control(maxdepth=3))
rpart.plot(mod.treeDepth)</code></pre>
<p><img src="Classification_files/figure-html/depth-1.png" width="672" /></p>
<pre class="r"><code>test$predicted = predict(mod.treeDepth, test, type=&#39;class&#39;)
mean(test$High == test$predicted) #accuracy</code></pre>
<pre><code>## [1] 0.7066667</code></pre>
<p>There is a small reduction in accuracy for this simpler model compared to the previous model.</p>
<p>Only split a sub-node if it contains at least 30 observations</p>
<pre class="r"><code>mod.treeObserve = rpart(High~.-Sales, carseats, subset=train, method=&#39;class&#39;, control=rpart.control(minsplit=30))
rpart.plot(mod.treeObserve)</code></pre>
<p><img src="Classification_files/figure-html/observe-1.png" width="672" /></p>
<pre class="r"><code>test$predicted = predict(mod.treeObserve, test, type=&#39;class&#39;)
mean(test$High == test$predicted) #accuracy</code></pre>
<pre><code>## [1] 0.7333333</code></pre>
<p>This model has similar accuracy to the un-pruned model, but is a less complicated tree.</p>
<p><strong>Post-Pruning:</strong> Here we grow a large tree then prune to balance error and complexity. Choose the left most value of complexity plot that lies below the line for the cp cutoff.</p>
<pre class="r"><code>set.seed(123)
mod.treeComplex = rpart(High~.-Sales, carseats, subset=train, method=&#39;class&#39;, control=rpart.control(cp=0))
rpart.plot(mod.treeComplex)</code></pre>
<p><img src="Classification_files/figure-html/post-1.png" width="672" /></p>
<pre class="r"><code>plotcp(mod.treeComplex)</code></pre>
<p><img src="Classification_files/figure-html/post-2.png" width="672" /></p>
<pre class="r"><code>mod.treeComplexPruned = prune(mod.treeComplex, cp=0.044)
rpart.plot(mod.treeComplexPruned)</code></pre>
<p><img src="Classification_files/figure-html/post-3.png" width="672" /></p>
<pre class="r"><code>test$predicted = predict(mod.treeComplexPruned, test, type=&#39;class&#39;)
mean(test$High == test$predicted) #accuracy</code></pre>
<pre><code>## [1] 0.7133333</code></pre>
<p>Despite being a simpler tree, this model still has similar accuracy to the full model.</p>
</div>
</div>
</div>
<div id="regression-tree-random-forest-housing-example" class="section level2">
<h2><span class="header-section-number">5.4</span> Regression Tree: Random Forest Housing Example</h2>
<pre class="r"><code>library(MASS)
library(randomForest)
boston = Boston
set.seed(101)
train = sample(1:nrow(boston), 300)
mod.rf = randomForest(medv~., data = boston, subset = train)
mod.rf</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = medv ~ ., data = boston, subset = train) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 4
## 
##           Mean of squared residuals: 12.68651
##                     % Var explained: 83.45</code></pre>
<p>The <em>randomForest</em> function defaults to growing 500 trees (ntree) and using <em>floor(ncol(data)/3)</em> variables (mtry) at each split.</p>
<div id="varying-the-number-of-variables" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Varying the Number of Variables</h3>
<p>Fit a random forest model with a variable mtry, calculate the out-of-bag error (based on training set) and the test error:</p>
<pre class="r"><code>oob.err = double(13)
test.err = double(13)
for (mtry in 1:13){
  mod.fit = randomForest(medv~., data=boston, subset=train, mtry=mtry, ntree=350)
  oob.err[mtry] = mod.fit$mse[350]
  pred = predict(mod.fit, boston[-train,])
  test.err[mtry] = with(boston[-train,], mean( (medv-pred)^2 ))
}</code></pre>
<pre class="r"><code>library(ggplot2)
mtryData = data.frame(mtry = 1:mtry, test.err, oob.err) %&gt;% pivot_longer(-mtry, names_to = &#39;ErrorType&#39;, values_to = &#39;Error&#39;)
ggplot(mtryData, aes(mtry, Error, color=ErrorType)) + geom_point() + geom_line() + theme(legend.position = c(0.9, 0.8))</code></pre>
<p><img src="Classification_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Mtry around 4 seems to be the most optimal choice, which is equivalent to <em>floor(13/3)</em>, the default choice for mtry.</p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
