<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Gradient Boosting</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Data Science</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Modeling
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Regression.html">Regression</a>
    </li>
    <li>
      <a href="Classification.html">Classification</a>
    </li>
    <li>
      <a href="Clustering.html">Clustering</a>
    </li>
    <li>
      <a href="Gradient-Boosting.html">Gradient Boosting</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Validation/Deployment
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Model-Validation.html">Model Validation</a>
    </li>
    <li>
      <a href="Model-Deployment.html">Model Deployment</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Additional Topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Databases.html">Databases</a>
    </li>
    <li>
      <a href="CloudComputing.html">Cloud Computing</a>
    </li>
    <li>
      <a href="ShellGit.html">Shell/Git</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Gradient Boosting</h1>

</div>

<div id="TOC">
<ul>
<li><a href="#overview"><span class="toc-section-number">1</span> Overview</a>
<ul>
<li><a href="#lightgbm-parameters"><span class="toc-section-number">1.1</span> LightGBM Parameters</a></li>
</ul></li>
<li><a href="#catboost-vs-lightgbm-vs-xgboost"><span class="toc-section-number">2</span> CatBoost vs LightGBM vs XGBoost</a>
<ul>
<li><a href="#growing-treesmaking-splits"><span class="toc-section-number">2.1</span> Growing trees/making splits</a></li>
<li><a href="#handling-data"><span class="toc-section-number">2.2</span> Handling Data</a></li>
<li><a href="#performance"><span class="toc-section-number">2.3</span> Performance</a></li>
<li><a href="#references"><span class="toc-section-number">2.4</span> References</a></li>
</ul></li>
</ul>
</div>

<div id="overview" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Overview</h1>
<p>Gradient boosting creates an ensemble of weak learners (typically decision trees), where each new tree is fit on a modified version of the original data set. At each stage we have an imperfect model <span class="math inline">\(F_m\)</span> and some new estimator (what the algorithm is adding) <span class="math inline">\(h_m(x)\)</span>, so <span class="math display">\[F_{m+1}(x) = F_m(x) + h_m(x) = y \]</span></p>
<p>We fit h to the residual, <span class="math inline">\(h_m(x) = y-F_m(x)\)</span>.</p>
<p>Many models are trained in a gradual, additive, and sequential manner. Gradient boosting identifies the shortcomings of the weak models using the gradients in the loss function.</p>
<div id="lightgbm-parameters" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> LightGBM Parameters</h2>
<p>Building off the table <a href="https://neptune.ai/blog/lightgbm-parameters-guide">here</a></p>
<p>Also see:</p>
<ul>
<li><p><a href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html">LightGBM parameter tuning doc</a></p></li>
<li><p><a href="https://github.com/microsoft/LightGBM/tree/master/R-package/demo">LightGBM R package</a></p></li>
<li><p><a href="https://modeloriented.github.io/EIX/reference/interactions.html">EIX: Using boosting to identify interactions</a></p></li>
<li><p><a href="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f">Bayesian Hyperparameter Optimization</a></p></li>
</ul>
<div id="fixed-parameters" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Fixed Parameters</h3>
<table>
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="37%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Name of parameter</strong></th>
<th align="left"><strong>Default value</strong></th>
<th align="left"><strong>Ranges</strong></th>
<th align="left"><strong>Notes</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">objective</td>
<td align="left">regression</td>
<td align="left">Regression, binary</td>
<td align="left">Affects other parameters</td>
</tr>
<tr class="even">
<td align="left">metric</td>
<td align="left">null</td>
<td align="left">+20 different metrics</td>
<td align="left">Null means that metric corresponding to specified objective will be used</td>
</tr>
<tr class="odd">
<td align="left">boosting</td>
<td align="left">gbdt</td>
<td align="left">gbdt, rf, dart, goss</td>
<td align="left">RF → bagging approach</td>
</tr>
<tr class="even">
<td align="left">categorical_feature</td>
<td align="left">Empty string</td>
<td align="left">Specify a number for a column index</td>
<td align="left">Handle categorical features</td>
</tr>
<tr class="odd">
<td align="left">bagging_freq</td>
<td align="left">0.0</td>
<td align="left">[0, ∞]</td>
<td align="left">0 means disable bagging; k means perform bagging at every k iteration</td>
</tr>
</tbody>
</table>
</div>
<div id="regularizationtraining-parameters" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Regularization/Training Parameters</h3>
<table>
<colgroup>
<col width="15%" />
<col width="15%" />
<col width="15%" />
<col width="27%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Name of parameter</strong></th>
<th align="left"><strong>Default value</strong></th>
<th align="left"><strong>Ranges</strong></th>
<th align="left"><strong>Notes</strong></th>
<th align="left"><strong>Tuning</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">bagging_fraction/subsample</td>
<td align="left">1.0</td>
<td align="left">[0, 1]</td>
<td align="left">Randomly select part of data without resampling</td>
<td align="left">Improves generalization and speed of training</td>
</tr>
<tr class="even">
<td align="left">feature_fraction</td>
<td align="left">1.0</td>
<td align="left">[0, 1]</td>
<td align="left">% of features on each tree</td>
<td align="left">Speeds up training, deals with overfitting</td>
</tr>
<tr class="odd">
<td align="left">num_leaves</td>
<td align="left">31</td>
<td align="left">[1, ∞]</td>
<td align="left">Max number of leaves in one tree</td>
<td align="left">Generally num_leaves = 2^(max_depth), but these too should be tuned together</td>
</tr>
<tr class="even">
<td align="left">max_depth</td>
<td align="left">-1</td>
<td align="left">[-1, ∞]</td>
<td align="left">Larger is usually better</td>
<td align="left">Too large → over fit</td>
</tr>
<tr class="odd">
<td align="left">max_bin</td>
<td align="left">255</td>
<td align="left">[2, ∞]</td>
<td align="left">Each continuous feature split into discrete bins</td>
<td align="left">Small is faster, larger more accurate</td>
</tr>
<tr class="even">
<td align="left">min_data_in_leaf</td>
<td align="left">20</td>
<td align="left">[0, ∞]</td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
</div>
<div id="other-parameters" class="section level3" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> Other Parameters</h3>
<table>
<colgroup>
<col width="15%" />
<col width="15%" />
<col width="15%" />
<col width="27%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Name of parameter</strong></th>
<th align="left"><strong>Default value</strong></th>
<th align="left"><strong>Ranges</strong></th>
<th align="left"><strong>Notes</strong></th>
<th align="left"><strong>Tuning</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">learning_rate</td>
<td align="left">0.1</td>
<td align="left">[0 1]</td>
<td align="left">Typical: 0.05</td>
<td align="left">Larger reduces training time</td>
</tr>
<tr class="even">
<td align="left">num_iterations/num_rounds/nrounds</td>
<td align="left">100</td>
<td align="left">[1, ∞]</td>
<td align="left">Number of trees to build</td>
<td align="left">Start small then increase, use smaller learning_rate and larger num_iterations</td>
</tr>
<tr class="odd">
<td align="left">early_stopping_round</td>
<td align="left">0</td>
<td align="left">[0, ∞]</td>
<td align="left">Will stop training if validation doesn’t improve in last early_stopping_round</td>
<td align="left">Generally 10% num_iterations</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="catboost-vs-lightgbm-vs-xgboost" class="section level1" number="2">
<h1><span class="header-section-number">2</span> CatBoost vs LightGBM vs XGBoost</h1>
<p>CatBoost and LightGBM are both gradient boosting methods, but differ in how they grow trees/make splits, handle missing data, and handle categorical data.</p>
<div id="growing-treesmaking-splits" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Growing trees/making splits</h2>
<p><strong>LightGBM:</strong></p>
<ul>
<li><p>(not default method) uses gradient based one side sampling (GOSS): selects splits using all the instances with large gradients/large errors and a random sample of instances with small gradients</p>
<ul>
<li><p>Also introduces a constant multiplier for the data with small gradients to keep the same data distribution when computing the information gain</p></li>
<li><p>Reduces number of data instances but keeps accuracy</p></li>
<li><p>Quickly finds the most influential cuts</p></li>
</ul></li>
<li><p>Uses leaf-wise (best-fit) tree growth: allows for imbalanced trees by choosing the leaf that minimizes the loss</p>
<ul>
<li>Overfitting can happen when data is small - control tree depth in this case</li>
</ul></li>
</ul>
<p><strong>CatBoost:</strong></p>
<ul>
<li><p>Grows oblivious trees: trees are grown by testing the same predictor with the same conditions on all nodes at the same level</p>
<ul>
<li>Minimal Variance Sampling (MVS): weighted sampling version of stochastic gradient boosting, weighted sampling happens in the tree-level and not in the split-level</li>
</ul></li>
<li><p>Default give symmetric/balanced trees: the feature-split pair that brings the lowest loss is selected and used for all the level’s nodes</p></li>
</ul>
<p><strong>XGBoost:</strong></p>
<ul>
<li><p>Similar to LightGBM it uses the gradients of different cuts to select the next cut, but also uses the hessian/second derivative to rank the cuts</p>
<ul>
<li>It uses a histogram based algorithm to split all the data points for a feature into discrete bins and uses these bins to find the split value of histogram</li>
</ul></li>
<li><p>Splits trees up to max_depth, then prunes backwards to remove splits without positive gain</p>
<ul>
<li>Can also grow leaf-wise</li>
</ul></li>
</ul>
</div>
<div id="handling-data" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Handling Data</h2>
<div id="missing-data" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Missing Data</h3>
<p><strong>Catboost:</strong></p>
<ul>
<li><p>Two options: min and max</p>
<ul>
<li><p>Missing values are processed as the minimum/maximum value for a feature (given a value less than/greater than all others)</p></li>
<li><p>Guaranteed to consider a split that separates missing values from all other values</p></li>
</ul></li>
</ul>
<p><strong>LightGBM/XGBoost:</strong></p>
<ul>
<li>Missing values are allocated to the side that reduces the loss in each split</li>
</ul>
</div>
<div id="categorical-data" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Categorical Data</h3>
<p><strong>XGBoost:</strong></p>
<ul>
<li>Encoding (one-hot, target encoding, etc) must be performed before training</li>
</ul>
<p><strong>LightGBM:</strong></p>
<ul>
<li><p>Could encode before training, or use built in method (gradient statistics) that doesn’t one-hot encode to find the split value of categorical features</p>
<ul>
<li><p>Encode categories during training instead of before: at each split decision for a node, categories are ordered by the amount of error they weigh in this node</p>
<ul>
<li><p>Compute gradients for every observation in the node</p></li>
<li><p>Summed squared gradients by category, use this to order the categories</p></li>
<li><p>Evaluate split possibilities in regard to gradient statistics</p></li>
</ul></li>
<li><p>Cons: computationally expensive, uses a lot of memory, gets worse with many categories</p>
<ul>
<li>Can group tail categories into one cluster if high cardinality</li>
</ul></li>
<li><p>This method isn’t necessarily better than encoding</p></li>
</ul></li>
</ul>
<p><strong>CatBoost:</strong></p>
<ul>
<li><p>Uses a combination of one-hot encoding (for features with a low number of categories) and advanced mean encoding:</p>
<ul>
<li><p>Permute set of input observation, multiple random permutations are generated</p></li>
<li><p>Convert label from floating point/category to integer</p></li>
<li><p>Iterate sequentially through the observations respecting new order: compute statistic using only observations seen in the past</p>
<ul>
<li><p>Statistic (for classification model) = <span class="math inline">\(avg target = \frac{count in class + prior}{total count + 1}\)</span></p></li>
<li><p>count_in_class = number of times in past training data the target = 1 for current categorical feature</p></li>
<li><p>total_count = total number of current categorical features in the past training</p></li>
<li><p>prior = constant number defined by starting parameters</p></li>
</ul></li>
<li><p>First observations have high variance because there’s little training data at the start of the iterations</p>
<ul>
<li>To fix: generate several random permutations, produce encoding for each, the average encodings</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="performance" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Performance</h2>
<ul>
<li><p>From reference 1: LightGBM, CatBoost and XGBoost were ~15x, 5x and 3x faster than GBM;</p>
<ul>
<li>In the baseline dataset, CatBoost outperforms the rest by 0.8–1%, other datasets had less significant differences</li>
</ul></li>
<li><p>From reference 2: CatBoost had best accuracy, minimum overfitting, and minimum prediction/tuning time → only worked well because there were categorical variables and they tuned one_hot_max_size</p>
<ul>
<li>XGBoost had good performance but very slow</li>
</ul></li>
</ul>
</div>
<div id="references" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> References</h2>
<ol style="list-style-type: decimal">
<li><p><a href="https://medium.com/riskified-technology/xgboost-lightgbm-or-catboost-which-boosting-algorithm-should-i-use-e7fda7bb36bc">CatBoost vs LightGBM vs XGBoost (better explanations)</a></p></li>
<li><p><a href="https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db">CatBoost vs LightGBM vs XGBoost (with code example)</a></p></li>
<li><p><a href="https://towardsdatascience.com/catboost-regression-in-6-minutes-3487f3e5b329">Intro to CatBoost (with example)</a></p></li>
<li><p><a href="https://catboost.ai/en/docs/concepts/parameter-tuning">CatBoost docs (parameter tuning)</a></p></li>
<li><p><a href="https://towardsdatascience.com/how-catboost-encodes-categorical-variables-3866fb2ae640">Catboost categorical encoding</a></p></li>
</ol>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
